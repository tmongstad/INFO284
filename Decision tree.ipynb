{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "df = pd.read_csv(\"GroupExam2024_data_and_documentation/elektronisk-rapportering-ers-2018-fangstmelding-dca-simple.csv\", sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree modell:\n",
    "- **Mål:** \n",
    "Utforske datasettet og prøve ut DecisionTreeRegressor.\n",
    "- **Bakgrunn:** \n",
    "Har utforsket havforskningsinstituttet sine kart og datatjenester og har gjort noen observasjoner angående fiske i havområdene rundt Norge.\n",
    "\n",
    "- **Tanker omkring forarbeid:**\n",
    "Ut fra karttjenestene til havforskningsinstituttet, ser vi at det foregår et omfattende sei-fiske - spesielt i områdene vest for Norge. Torskefiske, hvor torsk er hovedart foregår først og fremst i lofoten (uten trål) og i de nordligste områdene, kanskje spesielt rundt Bjørnøya.\n",
    "Ellers ser vi at de mest brukte fiskeredskapene er Bunntrål, Snurrevad og Andre liner. Bunntrål og snurrevad er relativt like redskaper i natur, så vi kunne vurdert å bruke modellen med begge disse redskapene. Valget faller likevel på bunntrål, siden det er mest representert i datasettet.\n",
    "\n",
    "Områdene vi har valgt å analysere er 8, 42, 28, og 7 som er områder vest for Bergen.\n",
    "Her er det hovedsaklig fiske etter Sei, og det er da naturlig å undersøke dette fiske, da det er nærliggende å anta at fiske etter ulik type fisk foregår i ulik dybde, lokasjoner, tidspunkt osv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21253 entries, 90 to 305299\n",
      "Data columns (total 45 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Melding ID                21253 non-null  int64  \n",
      " 1   Meldingstidspunkt         21253 non-null  object \n",
      " 2   Meldingsdato              21253 non-null  object \n",
      " 3   Meldingsklokkeslett       21253 non-null  object \n",
      " 4   Starttidspunkt            21253 non-null  object \n",
      " 5   Startdato                 21253 non-null  object \n",
      " 6   Startklokkeslett          21253 non-null  object \n",
      " 7   Startposisjon bredde      21253 non-null  float64\n",
      " 8   Startposisjon lengde      21253 non-null  float64\n",
      " 9   Hovedområde start (kode)  21253 non-null  float64\n",
      " 10  Hovedområde start         21253 non-null  object \n",
      " 11  Lokasjon start (kode)     21253 non-null  float64\n",
      " 12  Havdybde start            21253 non-null  int64  \n",
      " 13  Stopptidspunkt            21253 non-null  object \n",
      " 14  Stoppdato                 21253 non-null  object \n",
      " 15  Stoppklokkeslett          21253 non-null  object \n",
      " 16  Varighet                  21253 non-null  int64  \n",
      " 17  Fangstår                  21253 non-null  int64  \n",
      " 18  Stopposisjon bredde       21253 non-null  float64\n",
      " 19  Stopposisjon lengde       21253 non-null  float64\n",
      " 20  Hovedområde stopp (kode)  21253 non-null  float64\n",
      " 21  Hovedområde stopp         21253 non-null  object \n",
      " 22  Lokasjon stopp (kode)     21253 non-null  float64\n",
      " 23  Havdybde stopp            21253 non-null  int64  \n",
      " 24  Trekkavstand              21247 non-null  float64\n",
      " 25  Redskap FAO (kode)        21253 non-null  object \n",
      " 26  Redskap FAO               21253 non-null  object \n",
      " 27  Redskap FDIR (kode)       21253 non-null  float64\n",
      " 28  Redskap FDIR              21253 non-null  object \n",
      " 29  Hovedart FAO (kode)       21253 non-null  object \n",
      " 30  Hovedart FAO              21253 non-null  object \n",
      " 31  Hovedart - FDIR (kode)    21253 non-null  float64\n",
      " 32  Art FAO (kode)            21253 non-null  object \n",
      " 33  Art FAO                   21253 non-null  object \n",
      " 34  Art - FDIR (kode)         21253 non-null  float64\n",
      " 35  Art - FDIR                21253 non-null  object \n",
      " 36  Art - gruppe (kode)       21253 non-null  float64\n",
      " 37  Art - gruppe              21253 non-null  object \n",
      " 38  Rundvekt                  21253 non-null  float64\n",
      " 39  Lengdegruppe (kode)       21253 non-null  float64\n",
      " 40  Lengdegruppe              21253 non-null  object \n",
      " 41  Bruttotonnasje 1969       18983 non-null  float64\n",
      " 42  Bruttotonnasje annen      2270 non-null   float64\n",
      " 43  Bredde                    21253 non-null  float64\n",
      " 44  Fartøylengde              21253 non-null  float64\n",
      "dtypes: float64(19), int64(5), object(21)\n",
      "memory usage: 7.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Aktuelle redskaper å bruke: Bunntrål, Snurrevad og muligens Andre Liner. evt, dobbeltål\n",
    "# Unngå garn.\n",
    "# Aktuelle fisketyper å bruke hovedfangst: Sei\n",
    "fish_types = ['Sei']\n",
    "# Aktuelle Redskaper: Bunntrål, Snurrevad, Andre liner, (Dobbeltrål)\n",
    "tools = ['Bunntrål']  # , 'Snurrevad', 'Andre liner'\n",
    "# Aktuelle områder:\n",
    "#areas = [x for x in range(0, 70)] # alle hovedområder minus antarktis og fiske i andre hav.\n",
    "areas = [8, 42, 28, 7]\n",
    "\n",
    "condition_3 = df['Hovedområde start (kode)'].isin(areas)\n",
    "condition_1 = df['Hovedart FAO'].isin(fish_types) \n",
    "condition_2 = df['Redskap FDIR'].isin(tools)\n",
    "combined_condition = condition_1 & condition_2 & condition_3\n",
    "filtered_df = df[combined_condition].copy()\n",
    "filtered_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.loc[:, 'Bruttotonnasje kombinert'] = filtered_df['Bruttotonnasje 1969'].fillna(filtered_df['Bruttotonnasje annen'])\n",
    "\n",
    "for start_stop in ['Startklokkeslett', 'Stoppklokkeslett']:\n",
    "    # Konvertere klokkeslett til relevant verdi\n",
    "    filtered_df[start_stop] = pd.to_datetime(filtered_df[start_stop], format='%H:%M').dt.strftime('%H-%M')\n",
    "    # Konverter til Desimal-timer.\n",
    "    filtered_df[f'{start_stop}_DecimalHours'] = filtered_df[start_stop].str.split('-').apply(lambda x: int(x[0]) + int(x[1]) / 60)\n",
    "    # Konverter til Radianer.\n",
    "    filtered_df[f'{start_stop}_Radians'] = filtered_df[f'{start_stop}_DecimalHours'] * (2 * np.pi / 24)\n",
    "    # Regne ut sinus og cosinus.\n",
    "    filtered_df[f'{start_stop}_TimeSin'] = np.sin(filtered_df[f'{start_stop}_Radians'])\n",
    "    filtered_df[f'{start_stop}_TimeCos'] = np.cos(filtered_df[f'{start_stop}_Radians'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.drop(columns = [\n",
    "    'Fangstår', \n",
    "    #'Melding ID', \n",
    "    'Meldingstidspunkt', \n",
    "    'Meldingsdato',\n",
    "    'Meldingsklokkeslett', \n",
    "    'Starttidspunkt',\n",
    "    'Startklokkeslett',\n",
    "    #'Hovedområde start (kode)', \n",
    "    'Hovedområde start',\n",
    "    'Lokasjon start (kode)', \n",
    "    'Havdybde start', \n",
    "    'Stopptidspunkt',\n",
    "    'Varighet',\n",
    "    'Stoppdato', \n",
    "    'Startposisjon bredde',\n",
    "    'Startposisjon bredde',\n",
    "    #'Stoppklokkeslett', \n",
    "    #'Stopposisjon bredde', \n",
    "    #'Stopposisjon lengde',\n",
    "    'Hovedområde stopp (kode)', \n",
    "    'Hovedområde stopp',\n",
    "    'Lokasjon stopp (kode)', \n",
    "    'Redskap FAO (kode)', \n",
    "    'Redskap FDIR (kode)',\n",
    "    'Hovedart FAO (kode)',\n",
    "    'Hovedart - FDIR (kode)', \n",
    "    'Art FAO (kode)', \n",
    "    #'Art FAO',\n",
    "    'Art - FDIR (kode)', \n",
    "    'Art - FDIR', \n",
    "    'Art - gruppe (kode)',\n",
    "    #'Art - gruppe', \n",
    "    'Lengdegruppe (kode)', \n",
    "    'Lengdegruppe',\n",
    "    'Bredde',\n",
    "    'Fartøylengde',\n",
    "    'Bruttotonnasje 1969',\n",
    "    'Bruttotonnasje annen'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_unique_values(series):\n",
    "    return ', '.join(series.dropna().astype(str).unique())\n",
    "\n",
    "# Gruppere df og slå sammen rader som kommer av samme aktivitet:\n",
    "grouped_df = filtered_df.groupby(['Melding ID', 'Stoppklokkeslett'], as_index= False).agg({\n",
    "    'Stopposisjon lengde': 'first',\n",
    "    'Stopposisjon bredde': 'first',\n",
    "    'Stoppklokkeslett': 'first',\n",
    "    'Stoppklokkeslett_DecimalHours': 'first',\n",
    "    'Stoppklokkeslett_Radians': 'first',\n",
    "    'Stoppklokkeslett_TimeSin': 'first',\n",
    "    'Hovedområde start (kode)': 'first',\n",
    "    'Havdybde stopp': 'last',\n",
    "    'Trekkavstand': 'first',  \n",
    "    'Redskap FDIR': join_unique_values,\n",
    "    'Hovedart FAO': 'first',  \n",
    "    'Art FAO': join_unique_values,\n",
    "    'Art - gruppe': join_unique_values,\n",
    "    'Rundvekt': 'sum',   \n",
    "    'Bruttotonnasje kombinert': 'first'\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3889 entries, 0 to 5741\n",
      "Data columns (total 16 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   Melding ID                     3889 non-null   int64  \n",
      " 1   Stopposisjon lengde            3889 non-null   float64\n",
      " 2   Stopposisjon bredde            3889 non-null   float64\n",
      " 3   Stoppklokkeslett               3889 non-null   object \n",
      " 4   Stoppklokkeslett_DecimalHours  3889 non-null   float64\n",
      " 5   Stoppklokkeslett_Radians       3889 non-null   float64\n",
      " 6   Stoppklokkeslett_TimeSin       3889 non-null   float64\n",
      " 7   Hovedområde start (kode)       3889 non-null   float64\n",
      " 8   Havdybde stopp                 3889 non-null   int64  \n",
      " 9   Trekkavstand                   3889 non-null   float64\n",
      " 10  Redskap FDIR                   3889 non-null   object \n",
      " 11  Hovedart FAO                   3889 non-null   object \n",
      " 12  Art FAO                        3889 non-null   object \n",
      " 13  Art - gruppe                   3889 non-null   object \n",
      " 14  Rundvekt                       3889 non-null   float64\n",
      " 15  Bruttotonnasje kombinert       3889 non-null   float64\n",
      "dtypes: float64(9), int64(2), object(5)\n",
      "memory usage: 516.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Droppe tomme rader.\n",
    "cleaned_df = grouped_df.copy().dropna()\n",
    "# Konvertere positive Havdybdeverdier\n",
    "cleaned_df['Havdybde stopp'] = cleaned_df['Havdybde stopp'].abs()\n",
    "# Ta vekk havdybder på over 10 m, for å fjerne usannsynlige tråledybder.\n",
    "cleaned_df = cleaned_df[cleaned_df['Havdybde stopp'] > 10]\n",
    "# Droppe trekkavstand på over ei viss lengd.\n",
    "cleaned_df = cleaned_df[(cleaned_df['Trekkavstand'] > 10) & (cleaned_df['Trekkavstand'] < 60000)]\n",
    "\n",
    "# Droppe ekstreme Bruttotonnasjeverdier. Under\n",
    "cleaned_df = cleaned_df[(cleaned_df['Bruttotonnasje kombinert'] > 400) & (cleaned_df['Bruttotonnasje kombinert'] < 4000)]\n",
    "# Droppe registreringer i områder som ikkje er i Norsk farvatn. Startposisjon med mindre enn 0.\n",
    "cleaned_df = cleaned_df[cleaned_df['Stopposisjon lengde'] > 0]\n",
    "cleaned_df = cleaned_df[cleaned_df['Stopposisjon bredde'] > 0]\n",
    "cleaned_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Stopposisjon lengde</th>\n",
       "      <th>Stopposisjon bredde</th>\n",
       "      <th>Stoppklokkeslett_Radians</th>\n",
       "      <th>Havdybde stopp</th>\n",
       "      <th>Trekkavstand</th>\n",
       "      <th>Rundvekt</th>\n",
       "      <th>Bruttotonnasje kombinert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3889.000000</td>\n",
       "      <td>3889.000000</td>\n",
       "      <td>3889.000000</td>\n",
       "      <td>3889.000000</td>\n",
       "      <td>3889.000000</td>\n",
       "      <td>3889.000000</td>\n",
       "      <td>3889.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.661818</td>\n",
       "      <td>61.607083</td>\n",
       "      <td>3.061212</td>\n",
       "      <td>164.693494</td>\n",
       "      <td>12260.546156</td>\n",
       "      <td>8110.606068</td>\n",
       "      <td>1913.384160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.796194</td>\n",
       "      <td>1.473977</td>\n",
       "      <td>1.784911</td>\n",
       "      <td>52.827761</td>\n",
       "      <td>10511.577083</td>\n",
       "      <td>6639.417088</td>\n",
       "      <td>1093.746871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>57.462000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>430.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.374000</td>\n",
       "      <td>60.911000</td>\n",
       "      <td>1.518436</td>\n",
       "      <td>121.000000</td>\n",
       "      <td>4501.000000</td>\n",
       "      <td>3394.000000</td>\n",
       "      <td>691.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.335000</td>\n",
       "      <td>61.768000</td>\n",
       "      <td>3.006330</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>8882.000000</td>\n",
       "      <td>6711.000000</td>\n",
       "      <td>1874.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.318000</td>\n",
       "      <td>62.835000</td>\n",
       "      <td>4.581489</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>16816.000000</td>\n",
       "      <td>10700.000000</td>\n",
       "      <td>2580.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.576000</td>\n",
       "      <td>63.436000</td>\n",
       "      <td>6.226462</td>\n",
       "      <td>473.000000</td>\n",
       "      <td>57964.000000</td>\n",
       "      <td>55642.000000</td>\n",
       "      <td>3909.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Stopposisjon lengde  Stopposisjon bredde  Stoppklokkeslett_Radians  \\\n",
       "count          3889.000000          3889.000000               3889.000000   \n",
       "mean              3.661818            61.607083                  3.061212   \n",
       "std               1.796194             1.473977                  1.784911   \n",
       "min               0.001000            57.462000                  0.000000   \n",
       "25%               2.374000            60.911000                  1.518436   \n",
       "50%               3.335000            61.768000                  3.006330   \n",
       "75%               5.318000            62.835000                  4.581489   \n",
       "max               7.576000            63.436000                  6.226462   \n",
       "\n",
       "       Havdybde stopp  Trekkavstand      Rundvekt  Bruttotonnasje kombinert  \n",
       "count     3889.000000   3889.000000   3889.000000               3889.000000  \n",
       "mean       164.693494  12260.546156   8110.606068               1913.384160  \n",
       "std         52.827761  10511.577083   6639.417088               1093.746871  \n",
       "min         45.000000     50.000000     10.000000                430.000000  \n",
       "25%        121.000000   4501.000000   3394.000000                691.000000  \n",
       "50%        157.000000   8882.000000   6711.000000               1874.000000  \n",
       "75%        202.000000  16816.000000  10700.000000               2580.000000  \n",
       "max        473.000000  57964.000000  55642.000000               3909.000000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Lager en liste med features\n",
    "all_features = [\n",
    "    'Stopposisjon lengde', \n",
    "    'Stopposisjon bredde', \n",
    "    'Stoppklokkeslett_Radians', \n",
    "    'Havdybde stopp', \n",
    "    'Trekkavstand',  \n",
    "    'Rundvekt',\n",
    "    'Bruttotonnasje kombinert'\n",
    "]\n",
    "\n",
    "cleaned_df[all_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Target value: Stopposisjon lengde -------\n",
      "[5.601 2.968 3.191 5.401 1.614]\n",
      "1154    5.567\n",
      "3740    2.985\n",
      "4175    3.179\n",
      "2687    5.365\n",
      "185     1.586\n",
      "Name: Stopposisjon lengde, dtype: float64\n",
      "\n",
      "Mean absolute error: 0.12744344473007713\n",
      "\n",
      "--------- Target value: Stopposisjon bredde -------\n",
      "[62.733 60.485 59.655 63.11  61.68 ]\n",
      "1154    62.735\n",
      "3740    60.497\n",
      "4175    59.546\n",
      "2687    63.222\n",
      "185     61.635\n",
      "Name: Stopposisjon bredde, dtype: float64\n",
      "\n",
      "Mean absolute error: 0.1537814910025707\n",
      "\n",
      "--------- Target value: Stoppklokkeslett_Radians -------\n",
      "[0.01308997 3.08923278 5.86866961 0.01745329 2.79689013]\n",
      "1154    2.530727\n",
      "3740    4.886922\n",
      "4175    1.042834\n",
      "2687    5.183628\n",
      "185     1.282817\n",
      "Name: Stoppklokkeslett_Radians, dtype: float64\n",
      "\n",
      "Mean absolute error: 2.0614907106147546\n",
      "\n",
      "--------- Target value: Havdybde stopp -------\n",
      "[ 80. 113. 137. 247. 244.]\n",
      "1154     89\n",
      "3740    113\n",
      "4175    138\n",
      "2687    296\n",
      "185     277\n",
      "Name: Havdybde stopp, dtype: int64\n",
      "\n",
      "Mean absolute error: 10.196658097686376\n",
      "\n",
      "--------- Target value: Trekkavstand -------\n",
      "[29395.  7100.  6779. 11179. 25885.]\n",
      "1154     8542.0\n",
      "3740     9836.0\n",
      "4175    34425.0\n",
      "2687     1429.0\n",
      "185      2013.0\n",
      "Name: Trekkavstand, dtype: float64\n",
      "\n",
      "Mean absolute error: 9786.587403598971\n",
      "\n",
      "--------- Target value: Rundvekt -------\n",
      "[ 2585. 10797. 14435.  8023.  4968.]\n",
      "1154    10100.0\n",
      "3740    12477.0\n",
      "4175     4154.0\n",
      "2687     4142.0\n",
      "185      8061.0\n",
      "Name: Rundvekt, dtype: float64\n",
      "\n",
      "Mean absolute error: 5679.349614395887\n",
      "\n",
      "--------- Target value: Bruttotonnasje kombinert -------\n",
      "[1345. 2580. 1476.  536. 3909.]\n",
      "1154     567.0\n",
      "3740    1345.0\n",
      "4175    3104.0\n",
      "2687     536.0\n",
      "185     1345.0\n",
      "Name: Bruttotonnasje kombinert, dtype: float64\n",
      "\n",
      "Mean absolute error: 850.3598971722365\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # Importerer verktøy for å kalkulere feil i modellen - gjennomsnittlig feil?\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Lager en for-loop for å generere resultater for ulike target-values.\n",
    "for predict in all_features:\n",
    "    features = [f for f in all_features if f != predict]\n",
    "    X = cleaned_df[features]\n",
    "    y = cleaned_df[predict]\n",
    "\n",
    "    # Definerer X og y, X er features, y er målverdien (target value)\n",
    "    X = cleaned_df[features]\n",
    "    y = cleaned_df[predict]\n",
    "\n",
    "    # Splitter settet i trainsett og testsett - Da kan man sammenligne prediksjonene mot et test-sett\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    # Velger MLmodell\n",
    "    fishery_model = DecisionTreeRegressor(random_state=1)\n",
    "\n",
    "    # Trener(?) modellen på train-settet\n",
    "    fishery_model.fit(X_train, y_train)\n",
    "\n",
    "    # Prediksjoner - predikerer tar X-val verdiene og predikerer rundvekt basert på disse tallene.\n",
    "    val_predictions = fishery_model.predict(X_val)\n",
    "\n",
    "    # Sammenligner et utvalg (X-val.head()) av prediksjoner mot relaterte y_val.head()\n",
    "    print(f'--------- Target value: {predict} -------')\n",
    "    print(fishery_model.predict(X_val.head()))\n",
    "    print(y_val.head())\n",
    "   \n",
    "    # Tar inn y_val verdiene og regner ut gjennomsnittlig feil mellom prediksjonene og test-verdiene(val_y)\n",
    "    val_mae = mean_absolute_error(y_val, val_predictions)\n",
    "    print(f'\\nMean absolute error: {val_mae}\\n')\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ser her at det er ganske store variasjoner i prediksjonene. Det er forsåvidt naturlig i en så uforutsigbar bransje som fiskeri.\n",
    "Kan prøve med litt ulike feature og prediction values.\n",
    "Ser at modellen klarer å predikere havdybde og geografisk plassering av aktivitetene ganske godt. \n",
    "Dette gir kanskje mening da fiske av trål foregår i bestemte geografiske områder, og hvor havdybden er bestemt av nettopp geografisk plassering.\n",
    "\n",
    "Når det kommer til rundvekt, så er den ikke så treffsikker, men likevel ikke helt \"off\". Da fiskeri i seg selv er ganske uforutsigbart.\n",
    "\n",
    "### Vurderinger: \n",
    "- **Radians:** Vurdere andre måter å bruke tidsaspektet i modellen\n",
    "\n",
    "- **Rundvekt:** Dersom tidskolonnen ikke er god å bruke i modellen, kan det gi utslag på de andre prediksjonene.\n",
    "\n",
    "- **Trekkavstand:** Denne har jeg ikke så mange tanker omkring..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ChatGPTs vurdering av resultata:\n",
    "Given the descriptive statistics of your dataset, let's re-evaluate the prediction results of your Decision Tree Regressor for each feature, considering the mean, standard deviation (std), and range (min to max) of each:\n",
    "\n",
    "### Stopposisjon Lengde & Stopposisjon Bredde\n",
    "- **Stopposisjon Lengde MAE:** 0.127\n",
    "- **Stopposisjon Bredde MAE:** 0.154\n",
    "\n",
    "Given the standard deviations (1.796 for lengde, 1.474 for bredde) and the ranges (0.001 to 7.576 for lengde, 57.462 to 63.436 for bredde), the MAEs are very small in comparison. This indicates high accuracy in predictions relative to the variability of the data, showcasing the model's strong performance on these features.\n",
    "\n",
    "### Stoppklokkeslett_Radians\n",
    "- **MAE:** 2.061\n",
    "\n",
    "Considering the standard deviation (1.785) and the range (0 to 6.226), an MAE of 2.061 is significant but not excessively large, especially given the entire range of the data. It suggests moderate accuracy, which might be due to the cyclical nature of the feature that isn't well-captured by decision trees.\n",
    "\n",
    "### Havdybde Stopp\n",
    "- **MAE:** 10.197\n",
    "\n",
    "With a standard deviation of 52.828 and a range from 45 to 473, an MAE of 10.197 is relatively small, indicating the model's good performance in predicting the depth at which fishing stops occur.\n",
    "\n",
    "### Trekkavstand\n",
    "- **MAE:** 9786.587\n",
    "\n",
    "Given the standard deviation (10511.577) and the range (50 to 57964), while the MAE seems high, it's somewhat proportional to the variability and range of the data. However, this does indicate the predictions could be significantly off for individual instances, suggesting room for improvement in model performance or feature engineering for this variable.\n",
    "\n",
    "### Rundvekt\n",
    "- **MAE:** 5679.35\n",
    "\n",
    "With a substantial standard deviation (6639.417) and a wide range (10 to 55642), the MAE is somewhat high but still within the context of the data's variability. This suggests that while the model has predictive capability, there may be considerable error in specific predictions, reflecting the complexity or non-linear relationships within this feature.\n",
    "\n",
    "### Bruttotonnasje Kombinert\n",
    "- **MAE:** 850.36\n",
    "\n",
    "Given the standard deviation (1093.747) and the range (430 to 3909), the MAE is relatively high, suggesting that predictions can be off by a significant margin for many instances. This indicates a moderate level of accuracy, potentially impacted by the limited range of this feature compared to others.\n",
    "\n",
    "### Overall Evaluation:\n",
    "- **Good Performance:** For geographical features (lengde and bredde), the model is highly accurate.\n",
    "- **Moderate to Good:** For `Havdybde stopp`, the model shows good predictive capability, considering the data's variability.\n",
    "- **Needs Improvement:** For `Stoppklokkeslett_Radians`, `Trekkavstand`, `Rundvekt`, and `Bruttotonnasje kombinert`, the model's predictions show significant error margins. For `Trekkavstand` and `Rundvekt`, the high MAEs are notable given the large variability in these features. This might suggest that the model is capturing some, but not all, of the underlying patterns in the data.\n",
    "- **Considerations for Improvement:** Enhancements might include experimenting with different models, more sophisticated feature engineering (e.g., transforming features, adding interaction terms), or techniques to better capture the cyclical nature of time-based features. Additionally, evaluating model performance with other metrics and considering the distribution of errors could provide deeper insights into where and how the model might be improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions for the following 5 houses:\n",
      "   Stopposisjon lengde  Stopposisjon bredde  Stoppklokkeslett_Radians  \\\n",
      "0                2.134               61.278                  0.842121   \n",
      "1                1.982               61.343                  2.255838   \n",
      "2                1.702               61.552                  3.691371   \n",
      "3                1.885               61.401                  5.628687   \n",
      "4                5.664               63.401                  5.842490   \n",
      "\n",
      "   Havdybde stopp  Trekkavstand  Rundvekt  \n",
      "0             211       29124.0   30000.0  \n",
      "1             158        1972.0   17000.0  \n",
      "2             264       27885.0   20000.0  \n",
      "3             180       16590.0    3000.0  \n",
      "4             311       34192.0    1685.0  \n",
      "The predictions are\n",
      "[2053. 2053. 2053. 1199. 2053.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Making predictions for the following 5 houses:\")\n",
    "print(X.head())\n",
    "print(\"The predictions are\")\n",
    "print(fishery_model.predict(X.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170.1157109796863"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "predicted_round_weight = fishery_model.predict(X)\n",
    "mean_absolute_error(y, predicted_round_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mdrop([predict], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data[predict])\n\u001b[1;32m      4\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "X = np.array(data.drop([predict], axis=1))\n",
    "y = np.array(data[predict])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Apply Standardization\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x_train_scaled = min_max_scaler.fit_transform(x_train)\n",
    "x_test_scaled = min_max_scaler.transform(x_test)\n",
    "# For Min-Max Normalization, use MinMaxScaler() instead of StandardScaler()\n",
    "\n",
    "linear = linear_model.LinearRegression()\n",
    "linear.fit(x_train_scaled, y_train) # Use scaled data for training\n",
    "score = linear.score(x_test_scaled, y_test) # Evaluate the model using scaled test data\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[496], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data\u001b[38;5;241m.\u001b[39mdrop([predict], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     18\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data[predict])\n\u001b[0;32m---> 20\u001b[0m x_train, x_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43msklearn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_selection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m linear \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mLinearRegression()\n\u001b[1;32m     23\u001b[0m linear\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/info284/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/info284/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2617\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2614\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2616\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2617\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2618\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[1;32m   2619\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2622\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/info284/lib/python3.10/site-packages/sklearn/model_selection/_split.py:2273\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2270\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   2272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2274\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2275\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2276\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[1;32m   2277\u001b[0m     )\n\u001b[1;32m   2279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "areas = [x for x in range(0, 70)]\n",
    "\n",
    "for area in areas:\n",
    "    area_df = cleaned_df[cleaned_df['Hovedområde start (kode)'] == area]\n",
    "    features = [#'Stopposisjon lengde', \n",
    "                #'Stopposisjon bredde', \n",
    "                'Stoppklokkeslett_DecimalHours', \n",
    "                'Havdybde stopp', \n",
    "                'Trekkavstand',  \n",
    "                'Rundvekt',\n",
    "                'Bruttotonnasje kombinert'\n",
    "                ]\n",
    "\n",
    "    data = area_df[features]\n",
    "    predict = 'Rundvekt'\n",
    "\n",
    "    X = np.array(data.drop([predict], axis=1))\n",
    "    y = np.array(data[predict])\n",
    "\n",
    "    x_train, x_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "    linear = linear_model.LinearRegression()\n",
    "    linear.fit(x_train, y_train)\n",
    "    score = linear.score(x_test, y_test)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info284",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
