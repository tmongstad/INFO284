{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1703,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# import sklearn.datasets as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1704,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(305434, 45)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"GroupExam2024_data_and_documentation/elektronisk-rapportering-ers-2018-fangstmelding-dca-simple.csv\", sep=';', decimal=',')\n",
    "df.head()\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropped Meldingstidspunkt, Starttidspunkt, Art - FDIR and strings from dataset due to how the data scaling generaly dislikes strings!\n",
    "After dropping stings the scores went from -11% to 20%! (Both test and training) \n",
    "\n",
    "Maybe use one-hot encoding to include it anyway?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1705,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bruttotonnasje Gruppert\n",
       "6     992\n",
       "3     950\n",
       "2     618\n",
       "21    465\n",
       "4     433\n",
       "35    312\n",
       "14    305\n",
       "32    261\n",
       "5     257\n",
       "25    233\n",
       "1     210\n",
       "12    191\n",
       "16    186\n",
       "15    181\n",
       "40    164\n",
       "38     78\n",
       "26     50\n",
       "7      49\n",
       "23     45\n",
       "19     44\n",
       "45     17\n",
       "17      8\n",
       "42      5\n",
       "44      0\n",
       "46      0\n",
       "41      0\n",
       "33      0\n",
       "37      0\n",
       "36      0\n",
       "43      0\n",
       "34      0\n",
       "39      0\n",
       "24      0\n",
       "31      0\n",
       "30      0\n",
       "29      0\n",
       "28      0\n",
       "27      0\n",
       "22      0\n",
       "20      0\n",
       "18      0\n",
       "13      0\n",
       "11      0\n",
       "10      0\n",
       "9       0\n",
       "8       0\n",
       "47      0\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 1705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sile ut informasjon:\n",
    "df = df[(df['Art - FDIR (kode)'] == 1022) | (df['Art - FDIR (kode)'] == 1027)] # Fiske som fanger hyse eller torsk. \"751 - lodde, 1022 Torsk\"\n",
    "area = [7, 8, 28, 30, 40]\n",
    "df = df[(df['Redskap FDIR (kode)'] == 51) & (df['Hovedområde start (kode)'].isin(area))] # Fiske med bunntrål - 51, snurrevad - 11\n",
    "df['Bruttotonnasje Kombinert'] = df['Bruttotonnasje 1969'].fillna(df['Bruttotonnasje annen']) # Slår sammen kolonnene.\n",
    "# Dropper unødvendig informasjon. Tabellen inneholder masse duplikater. som egen kolonne for navn og for kode\n",
    "# Forskjellige klassifiseringsmåter. Holder på FDIR sine.\n",
    "\n",
    "# Normal pre-processing som vi gjorde på alt annet\n",
    "df.drop(columns = ['Meldingsdato', \n",
    "                   'Meldingsklokkeslett', \n",
    "                   'Startdato',  \n",
    "                   'Hovedområde start', \n",
    "                   'Lokasjon start (kode)', \n",
    "                   'Stoppdato', \n",
    "                   'Stoppklokkeslett', \n",
    "                   'Fangstår', \n",
    "                   'Hovedområde stopp (kode)', \n",
    "                   'Hovedområde stopp', \n",
    "                   'Lokasjon stopp (kode)', \n",
    "                   'Redskap FAO (kode)', \n",
    "                   'Redskap FAO', \n",
    "                   'Redskap FDIR', \n",
    "                   'Hovedart FAO (kode)', \n",
    "                   'Hovedart FAO', \n",
    "                   'Art FAO (kode)',\n",
    "                   'Art FAO',\n",
    "                   'Art - gruppe', \n",
    "                   'Lengdegruppe', \n",
    "                   'Bredde', \n",
    "                   'Fartøylengde',\n",
    "                   'Bruttotonnasje 1969',\n",
    "                   'Bruttotonnasje annen',\n",
    "\n",
    "                    #kolonner fjernet for MLP regressor\n",
    "                   'Meldingstidspunkt',\n",
    "                   'Starttidspunkt',\n",
    "                   'Startklokkeslett',\n",
    "                   'Stopptidspunkt',\n",
    "                   'Art - FDIR',\n",
    "                   'Melding ID',\n",
    "                   'Havdybde start',# Filter and remove incorrect values\n",
    "                   'Havdybde stopp',# Filter and remove incorrect values\n",
    "                   'Redskap FDIR (kode)', #Fjernet grunnet gjentagene data som ikke gav noe verdi\n",
    "                    'Hovedart - FDIR (kode)', #Fjernet grunnet gjentagene data som ikke gav noe verdi\n",
    "                    'Art - FDIR (kode)', #Fjernet grunnet gjentagene data som ikke gav noe verdi\n",
    "                    'Art - gruppe (kode)', #Fjernet grunnet gjentagene data som ikke gav noe verdi\n",
    "    ], inplace=True)\n",
    "\n",
    "# Gruppere bruttotonnasje:\n",
    "bins = [x for x in range(0, 4800, 100)] # Definerer gruppene\n",
    "labels = range(1, len(bins))  # nummererer gruppene.\n",
    "# Categorize 'Bruttotonnasje Kombinert' into the defined bins\n",
    "df['Bruttotonnasje Gruppert'] = pd.cut(df['Bruttotonnasje Kombinert'], bins=bins, labels=labels)\n",
    "# Teller grupperingene\n",
    "df['Bruttotonnasje Gruppert'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1706,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Startposisjon bredde</th>\n",
       "      <th>Startposisjon lengde</th>\n",
       "      <th>Hovedområde start (kode)</th>\n",
       "      <th>Varighet</th>\n",
       "      <th>Stopposisjon bredde</th>\n",
       "      <th>Stopposisjon lengde</th>\n",
       "      <th>Trekkavstand</th>\n",
       "      <th>Rundvekt</th>\n",
       "      <th>Lengdegruppe (kode)</th>\n",
       "      <th>Bruttotonnasje Kombinert</th>\n",
       "      <th>Bruttotonnasje Gruppert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>57.588</td>\n",
       "      <td>6.834</td>\n",
       "      <td>8.0</td>\n",
       "      <td>692</td>\n",
       "      <td>57.534</td>\n",
       "      <td>7.466</td>\n",
       "      <td>38303.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>61.221</td>\n",
       "      <td>2.181</td>\n",
       "      <td>28.0</td>\n",
       "      <td>330</td>\n",
       "      <td>61.481</td>\n",
       "      <td>1.753</td>\n",
       "      <td>36931.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2053.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>58.318</td>\n",
       "      <td>6.210</td>\n",
       "      <td>8.0</td>\n",
       "      <td>71</td>\n",
       "      <td>58.328</td>\n",
       "      <td>6.200</td>\n",
       "      <td>1259.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>58.318</td>\n",
       "      <td>6.210</td>\n",
       "      <td>8.0</td>\n",
       "      <td>71</td>\n",
       "      <td>58.328</td>\n",
       "      <td>6.200</td>\n",
       "      <td>1259.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>63.411</td>\n",
       "      <td>5.656</td>\n",
       "      <td>7.0</td>\n",
       "      <td>302</td>\n",
       "      <td>63.346</td>\n",
       "      <td>5.699</td>\n",
       "      <td>7558.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Startposisjon bredde  Startposisjon lengde  Hovedområde start (kode)  \\\n",
       "353                 57.588                 6.834                       8.0   \n",
       "635                 61.221                 2.181                      28.0   \n",
       "1000                58.318                 6.210                       8.0   \n",
       "1001                58.318                 6.210                       8.0   \n",
       "1149                63.411                 5.656                       7.0   \n",
       "\n",
       "      Varighet  Stopposisjon bredde  Stopposisjon lengde  Trekkavstand  \\\n",
       "353        692               57.534                7.466       38303.0   \n",
       "635        330               61.481                1.753       36931.0   \n",
       "1000        71               58.328                6.200        1259.0   \n",
       "1001        71               58.328                6.200        1259.0   \n",
       "1149       302               63.346                5.699        7558.0   \n",
       "\n",
       "      Rundvekt  Lengdegruppe (kode)  Bruttotonnasje Kombinert  \\\n",
       "353      114.0                  4.0                     267.0   \n",
       "635      100.0                  5.0                    2053.0   \n",
       "1000      10.0                  3.0                      79.0   \n",
       "1001       8.0                  3.0                      79.0   \n",
       "1149      72.0                  5.0                     536.0   \n",
       "\n",
       "     Bruttotonnasje Gruppert  \n",
       "353                        3  \n",
       "635                       21  \n",
       "1000                       1  \n",
       "1001                       1  \n",
       "1149                       6  "
      ]
     },
     "execution_count": 1706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1707,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6054, 11)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()\n",
    "y = df['Rundvekt'] \n",
    "X = df.drop('Rundvekt', axis=1) #Dropper rundvekt pga det er hva jeg trener modellen på\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1709,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_samples=200, random_state=1)\n",
    "# print(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1710,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2) #Test størrelse = 20% av datasettet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1711,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinMax Scaler fungerer best med MLP regressor grunnet at verdier som er ekstremt høye/lav kan føre til kluss i loss kalkuleringen\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# scaler.fit(X)\n",
    "# X = scaler.transform(X)\n",
    "X_train_minmax = scaler.fit_transform(X_train)\n",
    "X_test_minmax = scaler.fit_transform(X_test)\n",
    "\n",
    "# print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1712,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mildt sakt, standard scaler fungerte svært dårlig\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc=StandardScaler()\n",
    "\n",
    "# scaler = sc.fit(X_train)\n",
    "# X_train_scaled = scaler.transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1713,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "nn = MLPRegressor(hidden_layer_sizes = [20,10], #Første lag har 20 neurons, andre lag har 10. \n",
    "                  activation = 'relu', alpha = 0.1, \n",
    "                  max_iter = 2000, #Maks itterasjoner du gjør men det er egentlig epocs. usikker på hvorfor de bruker 'itterations' og not 'epocs'\n",
    "                #   early_stopping=True, #Early stopping introduserte ustabilitet. men med en iter på 2000 maks så skal det ikke ta alt for lang tid på de fleste pcer.\n",
    "                  learning_rate_init=0.1,#Start på learning rate, den blir adaptet etter hvert angående på loss verdien\n",
    "                  learning_rate=\"adaptive\",\n",
    "                  solver = 'adam', \n",
    "                  verbose = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1714,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural network, MLPRegressor\n",
      "Test score 0.707241424632056\n",
      "Train  score 0.942746221707945\n",
      "train minmax [0.64901324 0.70982269 0.54777129 0.2056272  0.13653067 0.55248075\n",
      " 0.52689285 0.33729798 0.51080482 0.20913965 0.52155672 0.23643919\n",
      " 0.45259559 0.73214865 0.60134079 0.35528118 0.49752182 0.54760864\n",
      " 0.65095313 0.48025504 0.59377543 0.42403629 0.7328132  0.93750971\n",
      " 0.59654453 0.44195873 0.68081658 0.57298198 0.22143087 0.\n",
      " 0.21793211 0.19208665 0.81682314 0.63981844 0.50328424 0.36491212\n",
      " 0.47247336 0.07389462 0.31925198 0.69094653 0.4891328  0.4502615\n",
      " 0.33714277 0.72871916 0.54705959 0.12901696 0.72408443 0.63531096\n",
      " 0.44529567 0.27132054 0.60139374 0.54242235 0.2838365  0.85928494\n",
      " 0.37633475 0.53022333 0.37325079 0.26774468 0.52893178 0.45792583\n",
      " 0.32469858 0.39583691 0.30239706 0.61099672 0.39163714 0.17890702\n",
      " 0.08823157 0.47185951 0.279634   0.16612655 0.84753618 0.52511866\n",
      " 0.79577888 0.33409658 0.23696592 0.74323173 0.50376923 0.56704559\n",
      " 0.3889209  0.64593144 0.43659257 0.60592765 0.92255857 0.60644246\n",
      " 0.24899975 0.74260419 0.4702289  0.37407556 0.63174675 0.51584882\n",
      " 0.5749608  0.60018776 0.57977365 0.55334779 0.19429324 0.6220782\n",
      " 0.50995421 0.16105036 0.28138458 0.37753815] y train 369.86251749978703\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Test skår uten data leak. (bruker minmax etter splitting)\n",
    "nn.fit(X_train_minmax, y_train)\n",
    "print(\"Neural network, MLPRegressor\")\n",
    "print(\"Test score\",  nn.score(X_test_minmax, y_test))\n",
    "print(\"Train  score\", nn.score(X_train_minmax, y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "important and relevant properties of the data\n",
    "how you preprocessed data like which features you selected, did you do dimension reduction,\n",
    "how you reformatted data, etc.\n",
    "how you decided on parameters for your machine learning models,\n",
    "if you used any regularization techniques? In case how.\n",
    "how the methods were measured and compared\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Endlig resultat\n",
    "Totalt så er det en overfitting problem som skaper problemer men ellers så er resultatene relativt gode. Det er klart ting som kan bli gjort bedre med preprocessing pga skåren noenganger er ganske lav. one-hot encoding kan hjelpe med dette gjennom å få tak i mer data samt med andre strategier som early stopping eller å minske mengen layers eg har (feks fra 2 layers med 20,10 til 1 layer med 7) og cross validation. Ting kan alltid bli forbedret men eg tror eg har nådd punktet der eg kommer til å se diminishing returns.\n",
    "Metoder ble målt og sammenlignet direkte fra training og test skår. Det var en data leak i skår test metoden helt opp mot slutten men generelt så ville ikke dette ha betydd alt for mye. før og etter eg fikset det så var skårene ganske like.\n",
    "\n",
    "\n",
    "Dataset features vi valgte\n",
    "Startposisjon bredde, Startposisjon lengde, Hovedområde start (kode), Varighet, Stopposisjon bredde, Stopposisjon lengde, Trekkavstand, Lengdegruppe (kode), Bruttotonnasje Kombinert, Bruttotonnasje Gruppert\n",
    "Rundvekt som trenings kolonne.\n",
    "generelt så ble disse valgt ut i fra testing med og uten verdien (opp til flere ganger for å se gjennomsnitt skår) og sunn fornuft som feks at det blir vansklig å finne rundvekt om du fjerner bruttotonnasje.\n",
    "\n",
    "Hvordan parameters ble valgt\n",
    "Ut i fra tester og søking på hva som er best til ett datasett som dette så ble parameterene valgt. Vi startet med en ting som fungerte og snevret inn etter hvert som vi fikset preprossesering.\n",
    "\n",
    "Vi brukte desverre ingen regularization techniques, men med tanke på at datasettet virker overfitted så ville nok early stopping vært lurt. men med å sette learning rate til \"adaptive\" så vil datasettet i teorien stoppe når optimum har blitt funnet. ved å introdusere early stopping så klusset det til hele systemet. mest sansynlig grunnet at de klusset med hverandre. Om vi hadde hat mer tid så ville regularization techniques mest sansynlig vis fikset ting og det er en god vei å gå om vi hadde gått videre.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Resultat test breakdown\n",
    "Test notater eg gjorde mens eg testet modellen. hver test har ca 10 gjennomkjøringer av regressoren med ulike endringer. endringer som var gode ble notert ned.\n",
    "\n",
    "Første test var bare for å se om ting fungerte riktig eller ikke. letteste måten å gjøre dette på er å fjerne en viktig verdi for å se om det påvirker datasettet på en kraftig måte.\n",
    "Test 1\n",
    "Fjernet 'Redskap FDIR (kode)', 'Bruttotonnasje Kombinert',\n",
    "Test score 0.22802640821841036\n",
    "Train  score 0.17609209269226367\n",
    "Eval: Ved å fjerne bruttotonnasje så går test og train skåren ned når du predikerer rundvekt. Dette kommer ikke som en overaskelse pga hvor viktig bruttotonnasje er for å indikere hvor mye fisk en båt kan fange\n",
    "Datasettet blir lest rett! (før fjerning test=31%, train=90%)\n",
    "\n",
    "Andre test var ett forsøk på å få skårene litt opp. Å øke iterations (epocs) til 100 000 max førte til bedre skår på kostnadden av en 3 min lang treningsperiode. Noa var klart gale!\n",
    "Seinere fant eg ut at Standard Scaler ikke fungerer bra med MLPRegressor og når eg hoppet over kunne eg senke iterations til 2000.\n",
    "Test 2\n",
    "Låg til scaler, økte iter til 100 000 (kan sikkert senkes til 10 000 etter optimaliseringer)\n",
    "Test score 0.3805415453308878\n",
    "Train  score 0.9885294076382664\n",
    "Klart overtrent men ting blir bedre!\n",
    "\n",
    "Tredje test var fjerning av repeterende koder og verdier som ikke gav nettverket noen unike verdier å trene på\n",
    "Test 3\n",
    "Fjernet: Hovedart - FDIR (kode), Art - FDIR (kode), Art - gruppe (kode)\n",
    "Test score 0.4551050579085447\n",
    "Train  score 0.9926394850239878\n",
    "Minimal økning, det var i alle fall ingen nedtur i nøyaktigheten. men den er enda overfitted\n",
    "\n",
    "\n",
    "Test 4\n",
    "Endringer: \n",
    "Endret fra standard scaler til minmax grunnet helt sprøe loss verdier som førte til ueffektivitet i antall epocs som kjørte. reduserte fra 10 000-60 000 epocs til ca 2000\n",
    "Fikset data leak i score kalkuleringen ved å minmax etter splitting\n",
    "Introduserte adaptiv learning rate.\n",
    "Endret fra \"sdg\" til \"adam\" solver i mlp regressor (slik at eg kan bruke adaptiv learning rate)\n",
    "Test score 0.707241424632056\n",
    "Train  score 0.942746221707945\n",
    "Klart overfitted men har ikke funnet en måte å fikse det på og vi begynner å gå tom for tid. evt ting som kan hjelpe med overfitting er å bruke early stopping før modellen når en optimal loss verdi. Det kan også være at one-hot encoding kan bli brukt for å få bedre data fra strings i datasettet eller annen preprossesering. Det er også mulig å redusere mengden lag og noder som blir skapt. det kan være at 20,10 er for mye (to lag, første med 20 noder, andre med 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
